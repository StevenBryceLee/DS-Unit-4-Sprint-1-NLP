{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LS_DS_422_BOW_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "U4S1-TEST",
      "language": "python",
      "name": "u4s1-test"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "nteract": {
      "version": "0.14.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenBryceLee/DS-Unit-4-Sprint-1-NLP/blob/main/module2-vector-representations/Copy_of_LS_DS_422_BOW_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE8QFDRZmcxx"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Vector Representations\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 2*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPkRb_ZYolz-",
        "outputId": "0e881fdb-1eb5-4671-d0e3-f333b86a5253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-1-NLP/main/requirements.txt\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-29 16:11:59--  https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-1-NLP/main/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 137 [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "requirements.txt    100%[===================>]     137  --.-KB/s    in 0s      \n",
            "\n",
            "2020-09-29 16:12:00 (9.76 MB/s) - ‘requirements.txt’ saved [137/137]\n",
            "\n",
            "Collecting gensim==3.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/dd/112bd4258cee11e0baaaba064060eb156475a42362e59e3ff28e7ca2d29d/gensim-3.8.1-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 1.3MB/s \n",
            "\u001b[?25hCollecting pyLDAvis==2.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 53.1MB/s \n",
            "\u001b[?25hCollecting spacy==2.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/13/80ad28ef7a16e2a86d16d73e28588be5f1085afd3e85e4b9b912bd700e8a/spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 47.9MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/7f/366dcba1ba076a88a50bea732dbc033c0c5bbf7876010e6edc67948579d5/scikit_learn-0.22.2-cp36-cp36m-manylinux1_x86_64.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 46.5MB/s \n",
            "\u001b[?25hCollecting seaborn==0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 42.6MB/s \n",
            "\u001b[?25hCollecting squarify==0.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/0b/2b/2e77c35326efec19819cd1d729540d4d235e6c2a3f37658288a363a67da5/squarify-0.4.3-py3-none-any.whl\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (4.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (3.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (1.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (4.6.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1->-r requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (0.35.1)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (2.11.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/66/89/479de0afbbfb98d1c4b887936808764627300208bb771fcd823403645a36/funcy-1.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (50.3.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (0.8.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (2.0.3)\n",
            "Collecting thinc<7.4.0,>=7.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/59/6bb553bc9a5f072d3cd479fc939fea0f6f682892f1f5cff98de5c9b615bb/thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from seaborn==0.9.0->-r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r requirements.txt (line 7)) (4.3.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r requirements.txt (line 7)) (5.3.5)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r requirements.txt (line 7)) (5.5.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r requirements.txt (line 7)) (5.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 9)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 9)) (2.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (8.5.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (1.9.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (20.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.3->-r requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy==2.2.3->-r requirements.txt (line 3)) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 3)) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0->-r requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->-r requirements.txt (line 7)) (4.4.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 7)) (19.0.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 7)) (4.6.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (1.0.18)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.2.3->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (0.2.5)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97712 sha256=0fc9e1b19b5ad0a788396fb81d392141050003ff79ef7ab1bc41214543a180dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "Successfully built pyLDAvis\n",
            "Installing collected packages: gensim, funcy, pyLDAvis, thinc, spacy, scikit-learn, seaborn, squarify\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: seaborn 0.11.0\n",
            "    Uninstalling seaborn-0.11.0:\n",
            "      Successfully uninstalled seaborn-0.11.0\n",
            "Successfully installed funcy-1.15 gensim-3.8.1 pyLDAvis-2.1.2 scikit-learn-0.22.2 seaborn-0.9.0 spacy-2.2.3 squarify-0.4.3 thinc-7.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAw5rGpxoq9R",
        "outputId": "052da844-ce94-402d-8878-322074d96d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.3.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.2.0)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp36-none-any.whl size=829180944 sha256=ddb7455da02d6b670a9ad0e299fc1d13e10e77f47da3ff8dc30736e7b0462769\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4fr_55xf/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyj-f9FDcVFp"
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3hCI1PTpacX"
      },
      "source": [
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7bcmqfGXrFG"
      },
      "source": [
        "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
        "\n",
        "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kz6-8m_qDYo",
        "outputId": "1d622e5d-7fca-4256-bc50-75b3d0433cd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-1-NLP/main/module2-vector-representations/data/job_listings.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-29 16:18:15--  https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-1-NLP/main/module2-vector-representations/data/job_listings.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1670819 (1.6M) [text/plain]\n",
            "Saving to: ‘job_listings.csv’\n",
            "\n",
            "job_listings.csv    100%[===================>]   1.59M  8.87MB/s    in 0.2s    \n",
            "\n",
            "2020-09-29 16:18:15 (8.87 MB/s) - ‘job_listings.csv’ saved [1670819/1670819]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcYlc1URXhlC"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "df = pd.read_csv('job_listings.csv')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib7g9HjXqg2E",
        "outputId": "4ac41dbb-848e-40d4-ee94-f82cef4ae98a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>description</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
              "      <td>Data scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
              "      <td>Data Scientist I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
              "      <td>Data Scientist - Entry Level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                         title\n",
              "0           0  ...               Data scientist \n",
              "1           1  ...              Data Scientist I\n",
              "2           2  ...  Data Scientist - Entry Level\n",
              "3           3  ...                Data Scientist\n",
              "4           4  ...                Data Scientist\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVOrcV7zrETg",
        "outputId": "125e4158-4b06-4e33-ed59-ea971323c128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "df.description[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'b\"<div><div>Job Requirements:</div><ul><li><p>\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them</p>\\\\n</li><li><p>Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)</p>\\\\n</li><li><p>Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R</p>\\\\n</li><li><p>Ability to communicate Model findings to both Technical and Non-Technical stake holders</p>\\\\n</li><li><p>Hands on experience in SQL/Hive or similar programming language</p>\\\\n</li><li><p>Must show past work via GitHub, Kaggle or any other published article</p>\\\\n</li><li><p>Master\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.</p></li></ul><div><div><div><div><div><div>\\\\nApply Now</div></div></div></div></div></div></div><div></div>\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p12hQigQrDN9",
        "outputId": "cb116aa0-5e0e-4231-ce75-28ed932b1e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "soup = BeautifulSoup(df.description[0])\n",
        "text = soup.get_text()\n",
        "text.replace('\\\\n',' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'b\"Job Requirements: Conceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role) Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R Ability to communicate Model findings to both Technical and Non-Technical stake holders Hands on experience in SQL/Hive or similar programming language Must show past work via GitHub, Kaggle or any other published article Master\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field. Apply Now\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xlzy3Mar2N5",
        "outputId": "2fafbc02-6f3c-41e3-cd2c-c327a8e1a3c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "new_col = df.description.apply(lambda x: BeautifulSoup(x).get_text().replace('\\\\n',' ').repla[1:])\n",
        "new_col.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    \"Job Requirements: Conceptual understanding in...\n",
              "1    'Job Description  As a Data Scientist 1, you w...\n",
              "2    'As a Data Scientist you will be working on co...\n",
              "3    '$4,969 - $6,756 a monthContractUnder the gene...\n",
              "4    'Location: USA \\xe2\\x80\\x93 multiple locations...\n",
              "Name: description, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oM0WBW_zkt9",
        "outputId": "72cdb9ac-d802-4653-e0aa-c7375c0db2fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "cleaned_col = new_col.apply(lambda x: re.sub('[^a-zA-Z ]', '', x))\n",
        "cleaned_col.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Job Requirements Conceptual understanding in M...\n",
              "1    Job Description  As a Data Scientist  you will...\n",
              "2    As a Data Scientist you will be working on con...\n",
              "3       a monthContractUnder the general supervisio...\n",
              "4    Location USA xexx multiple locations  years of...\n",
              "Name: description, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrfq_zbKsmAh"
      },
      "source": [
        "df['clean_description'] = cleaned_col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C4xFZNtX1m2"
      },
      "source": [
        "## 2) Use Spacy to tokenize the listings "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhUHuMr-X-II",
        "outputId": "6c7ce698-a300-41cb-ea28-984577816cad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from spacy.tokenizer import Tokenizer\n",
        "tokenizer = Tokenizer(nlp.vocab)\n",
        "\n",
        "tokens = []\n",
        "for doc in tokenizer.pipe(df['clean_description'], batch_size=500):\n",
        "    \n",
        "    doc_tokens = []\n",
        "    \n",
        "    for token in doc:\n",
        "        if (token.is_stop == False) & (token.is_punct == False) & (token.text is not ' '):\n",
        "            doc_tokens.append(token.lemma_.lower())\n",
        "\n",
        "    tokens.append(doc_tokens)\n",
        "\n",
        "df['tokens'] = tokens\n",
        "df['tokens'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [job, requirements, conceptual, understand, ma...\n",
              "1    [job, description, data, scientist, help, buil...\n",
              "2    [data, scientist, work, consult, business, res...\n",
              "3    [   , monthcontractunder, general, supervision...\n",
              "4    [location, usa, xexx, multiple, location, year...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLKD34-KzFDi",
        "outputId": "77c36129-e24d-4d63-fe16-696b91ecaee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df['tokens'][0][:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['job', 'requirements', 'conceptual', 'understand', 'machine']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lgCZNL_YycP"
      },
      "source": [
        "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYOhAz2b4ctk"
      },
      "source": [
        "df['joined_tokens'] = df['tokens'].apply(lambda x: ' '.join(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2PZ8Pj_YxcF"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# create the transformer\n",
        "vect = CountVectorizer()\n",
        "\n",
        "# build vocab\n",
        "vect.fit(df['joined_tokens'])\n",
        "\n",
        "# transform text\n",
        "dtm = vect.transform(df['joined_tokens'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvmE-dmZ1Iu1",
        "outputId": "02447d34-c1cb-4c28-dfc0-7d7b8a8f36fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "dtmdf = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
        "dtmdf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa</th>\n",
              "      <th>aaai</th>\n",
              "      <th>aaeeo</th>\n",
              "      <th>aas</th>\n",
              "      <th>ab</th>\n",
              "      <th>abernathy</th>\n",
              "      <th>abilities</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>abmultivariate</th>\n",
              "      <th>abound</th>\n",
              "      <th>abroad</th>\n",
              "      <th>absence</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>absorb</th>\n",
              "      <th>abstract</th>\n",
              "      <th>abstraction</th>\n",
              "      <th>abstractly</th>\n",
              "      <th>abtest</th>\n",
              "      <th>abundant</th>\n",
              "      <th>abuse</th>\n",
              "      <th>academia</th>\n",
              "      <th>academic</th>\n",
              "      <th>academy</th>\n",
              "      <th>accelerate</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>accelerator</th>\n",
              "      <th>accelerometer</th>\n",
              "      <th>accept</th>\n",
              "      <th>acceptable</th>\n",
              "      <th>acceptance</th>\n",
              "      <th>acceptapprove</th>\n",
              "      <th>acceptedcurrent</th>\n",
              "      <th>access</th>\n",
              "      <th>accessibility</th>\n",
              "      <th>accessible</th>\n",
              "      <th>accidental</th>\n",
              "      <th>accolade</th>\n",
              "      <th>accommodate</th>\n",
              "      <th>accommodation</th>\n",
              "      <th>...</th>\n",
              "      <th>years</th>\n",
              "      <th>yearsexperience</th>\n",
              "      <th>yearsummary</th>\n",
              "      <th>yearsxexx</th>\n",
              "      <th>yearthe</th>\n",
              "      <th>yeartitle</th>\n",
              "      <th>yearworking</th>\n",
              "      <th>yearxexxs</th>\n",
              "      <th>yes</th>\n",
              "      <th>yeti</th>\n",
              "      <th>yield</th>\n",
              "      <th>york</th>\n",
              "      <th>youd</th>\n",
              "      <th>youll</th>\n",
              "      <th>young</th>\n",
              "      <th>youre</th>\n",
              "      <th>yoursxexxis</th>\n",
              "      <th>youtube</th>\n",
              "      <th>youve</th>\n",
              "      <th>youxexx</th>\n",
              "      <th>youxexxaprotect</th>\n",
              "      <th>youxexxd</th>\n",
              "      <th>youxexxll</th>\n",
              "      <th>youxexxre</th>\n",
              "      <th>youxexxve</th>\n",
              "      <th>yr</th>\n",
              "      <th>zenreach</th>\n",
              "      <th>zero</th>\n",
              "      <th>zeus</th>\n",
              "      <th>zf</th>\n",
              "      <th>zfxexxs</th>\n",
              "      <th>zheng</th>\n",
              "      <th>zillow</th>\n",
              "      <th>zillows</th>\n",
              "      <th>zogsports</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zuckerberg</th>\n",
              "      <th>zurich</th>\n",
              "      <th>zurichxexxs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 8251 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   aa  aaai  aaeeo  aas  ab  ...  zone  zoom  zuckerberg  zurich  zurichxexxs\n",
              "0   0     0      0    0   0  ...     0     0           0       0            0\n",
              "1   0     0      0    0   0  ...     0     0           0       0            0\n",
              "2   0     0      0    0   0  ...     0     0           0       0            0\n",
              "3   0     0      0    0   0  ...     0     0           0       0            0\n",
              "4   0     0      0    0   0  ...     0     0           0       0            0\n",
              "\n",
              "[5 rows x 8251 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo1iH_UeY7_n"
      },
      "source": [
        "## 4) Visualize the most common word counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5LB00uyZKV5"
      },
      "source": [
        "x = [sum(dtmdf[col]) for col in dtmdf.columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4k85j8M2RBJ",
        "outputId": "aa879685-4f26-4b68-ba99-ab0c0eaabaed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "visSeries = pd.Series(x, index = dtmdf.columns).sort_values(ascending=False)\n",
        "visSeries.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datum         3393\n",
              "experience    1976\n",
              "work          1576\n",
              "team          1346\n",
              "business      1231\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItsVeW-12hVt",
        "outputId": "f06818a9-d781-42aa-a3b0-795ca33c7091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(9,13))\n",
        "plt.bar(visSeries.index[:10], visSeries.values[:10])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x936 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwFsTqrVZMYi"
      },
      "source": [
        "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r1RXcod5aMq"
      },
      "source": [
        "def tokenize(document):\n",
        "    \n",
        "    doc = nlp(document)\n",
        "    \n",
        "    return [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True) & (token.text is not ' ')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gx2gZCbl5Np",
        "outputId": "b6d7e997-09f8-4ad4-b0ae-1a4e34d7bae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Instantiate vectorizer object\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1,2),\n",
        "                        max_df=.97,min_df=3,\n",
        "                        tokenizer=tokenize)\n",
        "\n",
        "# Create a vocabulary and get word counts per document\n",
        "# Similiar to fit_predict\n",
        "dtm = tfidf.fit_transform(df['joined_tokens'])\n",
        "\n",
        "# Get feature names to use as dataframe column headers\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
        "\n",
        "# View Feature Matrix as DataFrame\n",
        "dtm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>experience</th>\n",
              "      <th>job</th>\n",
              "      <th>look</th>\n",
              "      <th>prefer</th>\n",
              "      <th>qualification</th>\n",
              "      <th>role</th>\n",
              "      <th>work</th>\n",
              "      <th>year</th>\n",
              "      <th>yearsxexx</th>\n",
              "      <th>ab</th>\n",
              "      <th>ab test</th>\n",
              "      <th>ability</th>\n",
              "      <th>ability analyze</th>\n",
              "      <th>ability apply</th>\n",
              "      <th>ability build</th>\n",
              "      <th>ability clearly</th>\n",
              "      <th>ability collaborate</th>\n",
              "      <th>ability communicate</th>\n",
              "      <th>ability create</th>\n",
              "      <th>ability deliver</th>\n",
              "      <th>ability develop</th>\n",
              "      <th>ability drive</th>\n",
              "      <th>ability effectively</th>\n",
              "      <th>ability experience</th>\n",
              "      <th>ability explain</th>\n",
              "      <th>ability identify</th>\n",
              "      <th>ability lead</th>\n",
              "      <th>ability learn</th>\n",
              "      <th>ability manage</th>\n",
              "      <th>ability perspective</th>\n",
              "      <th>ability present</th>\n",
              "      <th>ability require</th>\n",
              "      <th>ability solve</th>\n",
              "      <th>ability think</th>\n",
              "      <th>ability translate</th>\n",
              "      <th>ability understand</th>\n",
              "      <th>ability use</th>\n",
              "      <th>ability work</th>\n",
              "      <th>ability write</th>\n",
              "      <th>...</th>\n",
              "      <th>xcxbb experience</th>\n",
              "      <th>xcxbb familiarity</th>\n",
              "      <th>xefxx</th>\n",
              "      <th>xefxx communicate</th>\n",
              "      <th>xefxx deliver</th>\n",
              "      <th>xefxx endtoend</th>\n",
              "      <th>xefxx expertise</th>\n",
              "      <th>xefxx lead</th>\n",
              "      <th>xefxx run</th>\n",
              "      <th>xefxx vudu</th>\n",
              "      <th>xexx</th>\n",
              "      <th>xexx happen</th>\n",
              "      <th>xexxa</th>\n",
              "      <th>xexxbig</th>\n",
              "      <th>xexxcbig</th>\n",
              "      <th>xexxcbig dataxexxd</th>\n",
              "      <th>year</th>\n",
              "      <th>year analytic</th>\n",
              "      <th>year datum</th>\n",
              "      <th>year experience</th>\n",
              "      <th>year handson</th>\n",
              "      <th>year industry</th>\n",
              "      <th>year professional</th>\n",
              "      <th>year relate</th>\n",
              "      <th>year relevant</th>\n",
              "      <th>year work</th>\n",
              "      <th>yearsxexx</th>\n",
              "      <th>yearsxexx experience</th>\n",
              "      <th>yes</th>\n",
              "      <th>york</th>\n",
              "      <th>york city</th>\n",
              "      <th>youxexxll</th>\n",
              "      <th>youxexxll develop</th>\n",
              "      <th>youxexxll need</th>\n",
              "      <th>youxexxll partner</th>\n",
              "      <th>youxexxll work</th>\n",
              "      <th>youxexxre</th>\n",
              "      <th>youxexxre look</th>\n",
              "      <th>youxexxve</th>\n",
              "      <th>yr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.096994</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.118879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.141003</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021963</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.053838</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019654</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.046593</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.075772</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.156096</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.080824</td>\n",
              "      <td>0.303807</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              experience   job  ...  youxexxre look  youxexxve   yr\n",
              "0  0.000000          0.0   0.0  ...             0.0        0.0  0.0\n",
              "1  0.000000          0.0   0.0  ...             0.0        0.0  0.0\n",
              "2  0.000000          0.0   0.0  ...             0.0        0.0  0.0\n",
              "3  0.075772          0.0   0.0  ...             0.0        0.0  0.0\n",
              "4  0.000000          0.0   0.0  ...             0.0        0.0  0.0\n",
              "\n",
              "[5 rows x 5000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhqAZEs5mcyS"
      },
      "source": [
        "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "dRXYtb0SmcyT",
        "outputId": "d854a191-4ae6-4241-8be3-313bca2b76fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Fit on DTM\n",
        "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
        "nn.fit(dtm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
              "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                 radius=1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_7LNXRR7QfL"
      },
      "source": [
        "query = [df['joined_tokens'][334]]\n",
        "new = tfidf.transform(query)\n",
        "\n",
        "results = nn.kneighbors(new.todense())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW5WYPh999Yu",
        "outputId": "a0e29c79-dec8-4ed1-a8aa-fe5c3d3d5f50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results[0][0][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJKYo5r071Fc",
        "outputId": "636105d5-40f1-4d9f-b513-1712be8fbc10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "df['joined_tokens'][334]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'minimum qualification masters degree operations research industrial engineering statistics relate field equivalent practical experience year relevant work experience eg datum scientist equivalent analytical engagement outside class work school include experience statistical software eg r python database language eg sql preferred qualification phd operations research industrial engineering statistics relate field    year relevant work experience eg datum scientist include experience apply advance analytics plan infrastructure problem experience design build statistical forecast model experience design build machine learn model excellent problemframing problemsolving project management skill excellent customer service team collaboration skill job google datum drive decisionmaking data scientists work organization help shape googles business technical strategy process analyze interpret huge datum set analytic rigor statistical method datum identify opportunity google client operate efficiently enhance advertise efficacy network infrastructure optimization study user behavior analyst crunch number work engineers product managers sales associates marketing team adjust googles practice accord finding identifying problem half job figure solution member operations data science team apply operation research statistical method solve challenge relate compute storage network datacenter capacity googlexexxs internal service google cloud platform work broadly googlexexxs platforms engineering systems infrastructure site reliability engineering team optimize deployment resource drive innovation software stack allow efficient use resource data scientist think critically strategically googlexexxs cloud technology business operation comfortable discuss total cost management hardware engineer resource optimization software engineer review fleet plan deployment policy operation executive base analytic model develope user online architecture build technical infrastructure team run develope maintain datum center build generation google platform googles product portfolio possible proud engineer engineer love void warranty take thing apart rebuild network run ensure user well fast experience possible responsibilities lead project handson analysis model draw multiple analytic method choose right tool right level complexity appropriate business challenge engage broadly organization identify prioritize frame structure complex ambiguous challenge advance analytics project tool big impact identify communicate challenge opportunity group work help define analytic direction influence direction associate engineer infrastructure work articulate business question use mathematical technique arrive answer datum translate analysis result business recommendation google donxexxt accept differencexexxwe celebrate support thrive benefit employee product community google proud equal opportunity workplace affirmative action employer commit equal employment opportunity regardless race color ancestry religion sex national origin sexual orientation age citizenship marital status disability gender identity veteran status consider qualify applicant regardless criminal history consistent legal requirement googles eeo policy eeo law disability special need require accommodation let know complete form'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXSh-SYm8Ea6",
        "outputId": "f6e50bdd-f40b-4f72-81cb-d5c2f462d545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "df.iloc[[334, 275, 240, 359, 276],:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>description</th>\n",
              "      <th>title</th>\n",
              "      <th>clean_description</th>\n",
              "      <th>tokens</th>\n",
              "      <th>joined_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>334</td>\n",
              "      <td>b\"&lt;b&gt;Minimum qualifications:&lt;/b&gt;&lt;br/&gt;\\nMaster'...</td>\n",
              "      <td>Data Scientist, Operations Data Science</td>\n",
              "      <td>Minimum qualifications Masters degree in Opera...</td>\n",
              "      <td>[minimum, qualification, masters, degree, oper...</td>\n",
              "      <td>minimum qualification masters degree operation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>275</td>\n",
              "      <td>b\"&lt;b&gt;Minimum qualifications:&lt;/b&gt;&lt;br/&gt;\\nMaster'...</td>\n",
              "      <td>Data Scientist, Operations Data Science</td>\n",
              "      <td>Minimum qualifications Masters degree in Opera...</td>\n",
              "      <td>[minimum, qualification, masters, degree, oper...</td>\n",
              "      <td>minimum qualification masters degree operation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>240</td>\n",
              "      <td>b\"&lt;b&gt;Minimum qualifications:&lt;/b&gt;&lt;br/&gt;\\nMaster'...</td>\n",
              "      <td>Data Scientist, Operations Data Science</td>\n",
              "      <td>Minimum qualifications Masters degree in Opera...</td>\n",
              "      <td>[minimum, qualification, masters, degree, oper...</td>\n",
              "      <td>minimum qualification masters degree operation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>359</td>\n",
              "      <td>b'&lt;div&gt;&lt;p&gt;Maximizing our potential as a learni...</td>\n",
              "      <td>Sr. Data Scientist – Data for Insights Practice</td>\n",
              "      <td>Maximizing our potential as a learning organis...</td>\n",
              "      <td>[maximizing, potential, learn, organise, centr...</td>\n",
              "      <td>maximizing potential learn organise central me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>276</td>\n",
              "      <td>b\"&lt;div&gt;&lt;div&gt;&lt;div&gt;Facebook's mission is to give...</td>\n",
              "      <td>Data Scientist, Infrastructure</td>\n",
              "      <td>Facebooks mission is to give people the power ...</td>\n",
              "      <td>[facebooks, mission, people, power, build, com...</td>\n",
              "      <td>facebooks mission people power build community...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  ...                                      joined_tokens\n",
              "334         334  ...  minimum qualification masters degree operation...\n",
              "275         275  ...  minimum qualification masters degree operation...\n",
              "240         240  ...  minimum qualification masters degree operation...\n",
              "359         359  ...  maximizing potential learn organise central me...\n",
              "276         276  ...  facebooks mission people power build community...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiDfTWceoRkH"
      },
      "source": [
        "## Stretch Goals\n",
        "\n",
        " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
        " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
        " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
        " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
        "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
        " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlb2KypC0o4U"
      },
      "source": [
        "https://colab.research.google.com/drive/1-8OUgoAo5aKCXnSJnE6f_5iqMqOrs92m?usp=sharing#scrollTo=OqIahDThiHnF"
      ]
    }
  ]
}